{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "colab": {
      "name": "distilbert_semeval_run1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1414cb67f79a40d1958c13fae11c7cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6046ff8bdb949eaae21007c7126d39b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_785b5628bbe7484f9e0c75e070acd37a",
              "IPY_MODEL_cd83d2a1176a4e11bbede12e0149598e",
              "IPY_MODEL_00d6bd89dec94481a113d8e4877d9e0c"
            ]
          }
        },
        "f6046ff8bdb949eaae21007c7126d39b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "785b5628bbe7484f9e0c75e070acd37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd629ec788774b7892c97e395cd40886",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_33dcdbd0e4b34995a3848676bbd4a62f"
          }
        },
        "cd83d2a1176a4e11bbede12e0149598e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2313739c911240e9ac5ec17c7be9f30c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b83ad895ca38474da78b17c496789ad7"
          }
        },
        "00d6bd89dec94481a113d8e4877d9e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_baa1247be46a4841aa31f9d7889b1a5a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 1.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d4038c61bd8f4f1aa1bb1814218e0a04"
          }
        },
        "bd629ec788774b7892c97e395cd40886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "33dcdbd0e4b34995a3848676bbd4a62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2313739c911240e9ac5ec17c7be9f30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b83ad895ca38474da78b17c496789ad7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "baa1247be46a4841aa31f9d7889b1a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d4038c61bd8f4f1aa1bb1814218e0a04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ff80a98ca3642f2ba73bbacdc17a74f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_55ab24fa453748f28765dd7b6176ccc8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5925ca86e94c4b83b0c344ec629995fd",
              "IPY_MODEL_5137e727dc074a01b5abbabd4a353c93",
              "IPY_MODEL_7740d44323284511b78bff37cd4aee1f"
            ]
          }
        },
        "55ab24fa453748f28765dd7b6176ccc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5925ca86e94c4b83b0c344ec629995fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08a03ac77e7646e098a986b326545541",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c3e93d832b84456b5c1d92964e9a271"
          }
        },
        "5137e727dc074a01b5abbabd4a353c93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_290b00224c424bcab4ad237e1e38a6c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0830337f90dc4433b173b159d9936f39"
          }
        },
        "7740d44323284511b78bff37cd4aee1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_646372a1117a493ba3838a45b8f84fcc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 972B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec485c02075d466288a42d38a51d33b2"
          }
        },
        "08a03ac77e7646e098a986b326545541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c3e93d832b84456b5c1d92964e9a271": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "290b00224c424bcab4ad237e1e38a6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0830337f90dc4433b173b159d9936f39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "646372a1117a493ba3838a45b8f84fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec485c02075d466288a42d38a51d33b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db027e78ac5248eebc4362da51866418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_042e08fff6d04dfe8547dba5fb8160fa",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bd5d2e0e4394e33a7c868367542ccb3",
              "IPY_MODEL_1a05aa871560464a81b7839a7c6bf9f1",
              "IPY_MODEL_0097a729070044e9b96c87d4e96d33b8"
            ]
          }
        },
        "042e08fff6d04dfe8547dba5fb8160fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bd5d2e0e4394e33a7c868367542ccb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a026fd9f42bd4953b42e2906e404bc7b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aae0ca92c7d40e0b31595ced1b2aa6a"
          }
        },
        "1a05aa871560464a81b7839a7c6bf9f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b37d7a7076f84a91a97a1dccfdcb634e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_187287581a2c4e87af2eeebb83f6ad3b"
          }
        },
        "0097a729070044e9b96c87d4e96d33b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3e42913f27f346d79f6fdcfbe79c2feb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 1.12MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e5c119e5b5e245afaa7d6851ccadf23e"
          }
        },
        "a026fd9f42bd4953b42e2906e404bc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aae0ca92c7d40e0b31595ced1b2aa6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b37d7a7076f84a91a97a1dccfdcb634e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "187287581a2c4e87af2eeebb83f6ad3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e42913f27f346d79f6fdcfbe79c2feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e5c119e5b5e245afaa7d6851ccadf23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b39a08e09424a4caf76b40cf02425b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_41cc5f4c3d804548a743524efe8774b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3700f0b2044b4e0cb42e66f1933fdad8",
              "IPY_MODEL_df01db37588943bb96d2a4e1f7ac41c3",
              "IPY_MODEL_49fc123979974188b96befbaad7cf96e"
            ]
          }
        },
        "41cc5f4c3d804548a743524efe8774b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3700f0b2044b4e0cb42e66f1933fdad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_205170b224fa4a4f8be3039eb8344e25",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a351ef5d72834407b5e84ba8ec429b7a"
          }
        },
        "df01db37588943bb96d2a4e1f7ac41c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8cbe91dd2f8640c9a1553cdd2dd0afc8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de1cf9289d3843ed93ba12295fc3c967"
          }
        },
        "49fc123979974188b96befbaad7cf96e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35b92656520749c891b53df6f4d33511",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 15.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e6eb4940d014539b0bbfb2bdb3811d1"
          }
        },
        "205170b224fa4a4f8be3039eb8344e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a351ef5d72834407b5e84ba8ec429b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8cbe91dd2f8640c9a1553cdd2dd0afc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de1cf9289d3843ed93ba12295fc3c967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35b92656520749c891b53df6f4d33511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e6eb4940d014539b0bbfb2bdb3811d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7fd8bd2746cd47d78c1da902352c214c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f311d86da606466a84d8b2cd7c848307",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03a665462ca04b069fd9ede5c100b9e7",
              "IPY_MODEL_d3724f9c07b14073a129ef0ff1d1eef0",
              "IPY_MODEL_89bd68bb5a6e4882a8e7cfed1bbdddbd"
            ]
          }
        },
        "f311d86da606466a84d8b2cd7c848307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03a665462ca04b069fd9ede5c100b9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35e47b1f49eb45f5990f4f960465758a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02f957beded84771b0bb4c4aed91a327"
          }
        },
        "d3724f9c07b14073a129ef0ff1d1eef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7b7e98292cee44938e5143a05b6e8a4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_074b808445254306a0b8b2b8fe547069"
          }
        },
        "89bd68bb5a6e4882a8e7cfed1bbdddbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e3c29470b704cddbe9ed5161a0fb971",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 256M/256M [00:07&lt;00:00, 34.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_408745d17ad247239760cd90cca8669c"
          }
        },
        "35e47b1f49eb45f5990f4f960465758a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02f957beded84771b0bb4c4aed91a327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7b7e98292cee44938e5143a05b6e8a4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "074b808445254306a0b8b2b8fe547069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4e3c29470b704cddbe9ed5161a0fb971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "408745d17ad247239760cd90cca8669c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nazmus007/transformers_test/blob/main/distilbert_semeval_run1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTQvMtWsztpa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed13b75-e71f-4ec3-de07-49069d62a8c4"
      },
      "source": [
        " !pip install -qq transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.9 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 49.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 31.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "rQls5xsYO8YP",
        "outputId": "c6ca3917-7ce9-43f3-9651-ac77fa6afaff"
      },
      "source": [
        "print(transformers.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-de6040bb8a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'transformers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8OREO3n6Ft-",
        "outputId": "8c265d86-c633-4c01-f211-62dedb9d2136"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-1.6.0.tar.gz (168 kB)\n",
            "\u001b[?25l\r\u001b[K     |██                              | 10 kB 25.7 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 20 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 40 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 92 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 168 kB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.0-py3-none-any.whl size=168256 sha256=82b026207fbebd37e2fa86543cebc59bf913ba80513566ed23a29ee420661dc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/d7/74/c720aaf345a042b0c2d74361873258c5e8649b7f11b2ccce49\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xreQ6mWHPS1R"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31C71en6z4IP",
        "outputId": "babbb50c-0c84-404a-ffed-16c53b8483c3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKnXhS4-X3aQ",
        "outputId": "fde70024-98dd-4f7f-ebfd-7103dc7420bb"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▋                        | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 20 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 40 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 1.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FZSJGtBOSvi",
        "outputId": "ad17db5a-28c4-4ce3-99ad-44e9f4d122e8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 30 13:07:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541801096
        },
        "id": "CO7SFj5Xztpf"
      },
      "source": [
        "import transformers\n",
        "\n",
        "from transformers import DistilBertModel, DistilBertTokenizer, AdamW, get_linear_schedule_with_warmup, DistilBertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from pylab import rcParams\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from matplotlib import rc\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "from collections import defaultdict\n",
        "\n",
        "from textwrap import wrap\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import emoji"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541914487
        },
        "id": "p9fpcDXTztpg"
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541916842
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0AbDURbSztph",
        "outputId": "f52c8b54-10e7-4c4a-e8e2-3abf56d9fac0"
      },
      "source": [
        "df = pd.read_csv(\"./drive/MyDrive/datasets/cleaned_semeval_wnotebook_5.csv\")\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet index</th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>sweet united nations video just in time for ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>we are rumored to have talked to erv is agent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>hey there nice to see you minnesotand winter w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left i am dying over here</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>i cannot breathe was chosen as the most notabl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tweet index  Label                                              Tweet\n",
              "0            1      1  sweet united nations video just in time for ch...\n",
              "1            2      1  we are rumored to have talked to erv is agent ...\n",
              "2            3      1  hey there nice to see you minnesotand winter w...\n",
              "3            4      0               3 episodes left i am dying over here\n",
              "4            5      1  i cannot breathe was chosen as the most notabl..."
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541920084
        },
        "id": "D3arVKEGztpj"
      },
      "source": [
        "df = df.drop(['Tweet index'],axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbbU-dHXfTcH"
      },
      "source": [
        "df.dropna(subset = [\"Tweet\"], inplace=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv-CoVFDftrJ"
      },
      "source": [
        "import emoji\n",
        "def extract_emojis(s):\n",
        "    return ''.join((' '+c+' ') if c in emoji.UNICODE_EMOJI['en'] else c for c in s)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B2p5B8sfykG"
      },
      "source": [
        "df['Tweet'] = df['Tweet'].apply(extract_emojis)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y60t6wSYf3LP"
      },
      "source": [
        "df.columns = df.columns.str.lstrip()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYjOwg5hgB-W"
      },
      "source": [
        "pd.options.display.max_colwidth = 130"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "3bC_RZuQgJ-0",
        "outputId": "f2568e83-a29c-45bd-f12f-d8e0be3439b6"
      },
      "source": [
        "df.iloc[1959:1967]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>1</td>\n",
              "      <td>so glad they have found a way to make the gospel socially relevant to klingons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>0</td>\n",
              "      <td>oo ummmso like rt from our family to yours have a safe and happythanksgiving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>0</td>\n",
              "      <td>my death will likely be caused by  at the wrong time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>0</td>\n",
              "      <td>everybody just keeps saying gronk and large contingent of patriots who else is there with rob</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>1</td>\n",
              "      <td>dad and step mom bitching at each other now it is christmas  😊  🎄  😤   disgusted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>1</td>\n",
              "      <td>internet got me like  😩  stillalive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1965</th>\n",
              "      <td>1</td>\n",
              "      <td>the joy i have for overnight stakeouts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1967</th>\n",
              "      <td>1</td>\n",
              "      <td>gutted doyle has gone back to wwfc i do not think we saw what he is capable of cpfc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Label                                                                                          Tweet\n",
              "1959      1                 so glad they have found a way to make the gospel socially relevant to klingons\n",
              "1960      0                   oo ummmso like rt from our family to yours have a safe and happythanksgiving\n",
              "1961      0                                           my death will likely be caused by  at the wrong time\n",
              "1962      0  everybody just keeps saying gronk and large contingent of patriots who else is there with rob\n",
              "1963      1               dad and step mom bitching at each other now it is christmas  😊  🎄  😤   disgusted\n",
              "1964      1                                                            internet got me like  😩  stillalive\n",
              "1965      1                                                         the joy i have for overnight stakeouts\n",
              "1967      1            gutted doyle has gone back to wwfc i do not think we saw what he is capable of cpfc"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOtRJofY3iNX"
      },
      "source": [
        "emoji_1 = re.compile('[\\\\u203C-\\\\u3299\\\\U0001F000-\\\\U0001F644]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0xz4FhI5Vyt"
      },
      "source": [
        "emoji_list= list(filter(emoji_1.match, df['Tweet text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJq2I3YhAc-R"
      },
      "source": [
        "def extract_emojis(text):\n",
        "    return ''.join(c for c in text if c in emoji.UNICODE_EMOJI)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf4s4OkxApc1"
      },
      "source": [
        "df['emoji_apply'] = df['Tweet text'].apply(extract_emojis)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "UhJ0AwvGBDYZ",
        "outputId": "20ef8aaa-21dd-41db-e7ca-5cbf486a1845"
      },
      "source": [
        "df.head(25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet text</th>\n",
              "      <th>emoji_apply</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sweet united nations video just in time for ch...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>we are rumored to have talked to erv is agent...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hey there nice to see you minnesotand winter w...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left i am dying over here</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>i cannot breathe was chosen as the most notabl...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>you are never too old for footie pajamas</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>nothing makes me happier then getting on the h...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>430 an opening my first beer now gonna be a lo...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>do you think you would support a guy who knoc...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>you are not allowed to open that until christ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>oh thank god  our entire office email system i...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>but instead i am scrolling through facebook in...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>😡 no he bloody is not i was upstairs getting ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>cold or warmth both suffuse one is cheeks with...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>just great when you are mobile bill arrives by...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>crushes are great until you realize they will ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>buffalo sports media is smarter than all of us...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>i guess my cat also lost 3 pounds when she wen...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>trading a sp for a defenseonly ss brilliant ...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>but  was trying to find us and my battery died...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>please doi need the second hand embarrassment...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>i never cared for beyonce bc i could never get...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>time to hit the books then</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>thx4flw flwthemusic   we are elektrikbloom el...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>love these cold winter mornings 😬 best feeling...</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Label                                         Tweet text emoji_apply\n",
              "0       1  sweet united nations video just in time for ch...            \n",
              "1       1   we are rumored to have talked to erv is agent...            \n",
              "2       1  hey there nice to see you minnesotand winter w...            \n",
              "3       0               3 episodes left i am dying over here            \n",
              "4       1  i cannot breathe was chosen as the most notabl...            \n",
              "5       0          you are never too old for footie pajamas             \n",
              "6       1  nothing makes me happier then getting on the h...            \n",
              "7       0  430 an opening my first beer now gonna be a lo...            \n",
              "8       0   do you think you would support a guy who knoc...            \n",
              "9       0   you are not allowed to open that until christ...            \n",
              "10      1  oh thank god  our entire office email system i...            \n",
              "11      0  but instead i am scrolling through facebook in...            \n",
              "12      0   😡 no he bloody is not i was upstairs getting ...            \n",
              "13      0  cold or warmth both suffuse one is cheeks with...            \n",
              "14      1  just great when you are mobile bill arrives by...            \n",
              "15      1  crushes are great until you realize they will ...            \n",
              "16      1  buffalo sports media is smarter than all of us...            \n",
              "17      0  i guess my cat also lost 3 pounds when she wen...            \n",
              "18      1    trading a sp for a defenseonly ss brilliant ...            \n",
              "19      1  but  was trying to find us and my battery died...            \n",
              "20      1   please doi need the second hand embarrassment...            \n",
              "21      0  i never cared for beyonce bc i could never get...            \n",
              "22      1                        time to hit the books then             \n",
              "23      0   thx4flw flwthemusic   we are elektrikbloom el...            \n",
              "24      1  love these cold winter mornings 😬 best feeling...            "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCKGRk-06NXC"
      },
      "source": [
        "emoji_list= list(filter(emoji_1.match, df['Tweet text']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3xabioA5e-Y",
        "outputId": "4f552bc9-44cc-4e8e-8a59-4992628c0a4c"
      },
      "source": [
        "print(emoji_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['👊 fistbump positive focus starve distractions werk motivation createpath uplift success ', '😒 half of the testing group was very helpful today ', '🙀😱🙀😱🙀😱 popcorn 😂🎅😂🎅😂🔫🔫 bringing this at movie tuesday night  ', '🇫🇴🇱🇱🇴🇼 thistsu website now worth 15 millionyou get paid for posting ', '😂😂 i will let you and bb know how i get on xx', '🎉it is monday 🎉 ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev1FyCD87SxC"
      },
      "source": [
        "emo_found= ' '.join(emoji for emoji in emoji_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8GjMz7F9Otc"
      },
      "source": [
        "from emoji import UNICODE_EMOJI\n",
        "\n",
        "def get_emoji_set(text):\n",
        "    return {letter for letter in text if letter in UNICODE_EMOJI['en'] }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBt3k70f930z"
      },
      "source": [
        "c = get_emoji_set(emo_found)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgL3XTIDCAWV",
        "outputId": "e28fa1c9-c030-4af5-f371-4e56de8478c8"
      },
      "source": [
        "print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'🙀', '🎉', '🎅', '👊', '😂', '😱', '😒', '🔫'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbd2ndxV7L9o",
        "outputId": "b455ecaa-155c-466b-c883-4433e5ffbe96"
      },
      "source": [
        "!pip install demoji"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting demoji\n",
            "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▋                        | 10 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 20 kB 23.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 42 kB 780 kB/s \n",
            "\u001b[?25hInstalling collected packages: demoji\n",
            "Successfully installed demoji-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqMI43WWhTE0"
      },
      "source": [
        "import demoji\n",
        "def demoji_text(text):\n",
        "  d= demoji.findall(text)\n",
        "  return d\n",
        "  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZOH1S3PhqxN"
      },
      "source": [
        "df['emoji_list'] = df['Tweet'].apply(demoji_text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "djmZU2iOh_qF",
        "outputId": "0e468b87-cd46-4911-9211-e5fc6967322f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>emoji_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sweet united nations video just in time for christmas imagine noreligion</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>we are rumored to have talked to erv is agent and the angels asked about ed escobar that is hardly nothing</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hey there nice to see you minnesotand winter weather</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left i am dying over here</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>i cannot breathe was chosen as the most notable quote of the year in an annual list released by a yale university librarian</td>\n",
              "      <td>{}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label  ... emoji_list\n",
              "0      1  ...         {}\n",
              "1      1  ...         {}\n",
              "2      1  ...         {}\n",
              "3      0  ...         {}\n",
              "4      1  ...         {}\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOCo9oAUnjr5"
      },
      "source": [
        "f= list(filter(None, df['emoji_list']))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoMJfwlZny7N",
        "outputId": "d5b3a794-3e78-4123-aa52-88a976a2ccfa"
      },
      "source": [
        "print(f)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'😡': 'pouting face'}, {'😬': 'grimacing face'}, {'❤': 'red heart'}, {'😅': 'grinning face with sweat'}, {'😁': 'beaming face with smiling eyes'}, {'😐': 'neutral face'}, {'😱': 'face screaming in fear'}, {'☺': 'smiling face', '👭': 'women holding hands'}, {'😳': 'flushed face', '💯': 'hundred points'}, {'😴': 'sleeping face'}, {'💩': 'pile of poo'}, {'😩': 'weary face'}, {'😑': 'expressionless face'}, {'🎶': 'musical notes'}, {'😇': 'smiling face with halo', '😃': 'grinning face with big eyes'}, {'😂': 'face with tears of joy'}, {'🙌': 'raising hands'}, {'😲': 'astonished face', '😂': 'face with tears of joy'}, {'✈': 'airplane', '❤': 'red heart', '🌏': 'globe showing Asia-Australia'}, {'😘': 'face blowing a kiss', '😍': 'smiling face with heart-eyes'}, {'😘': 'face blowing a kiss', '😍': 'smiling face with heart-eyes', '😳': 'flushed face'}, {'🎶': 'musical notes', '☀': 'sun'}, {'🙊': 'speak-no-evil monkey'}, {'😭': 'loudly crying face'}, {'😩': 'weary face'}, {'🌴': 'palm tree', '☀': 'sun'}, {'😀': 'grinning face', '🔫': 'water pistol'}, {'😩': 'weary face'}, {'🎶': 'musical notes', '😆': 'grinning squinting face', '🎅': 'Santa Claus', '🎉': 'party popper'}, {'🍷': 'wine glass'}, {'👎': 'thumbs down', '💦': 'sweat droplets', '💧': 'droplet', '💨': 'dashing away'}, {'😃': 'grinning face with big eyes'}, {'🙈': 'see-no-evil monkey'}, {'😫': 'tired face', '😷': 'face with medical mask'}, {'😆': 'grinning squinting face'}, {'😫': 'tired face'}, {'😂': 'face with tears of joy'}, {'✌': 'victory hand'}, {'😉': 'winking face'}, {'💅': 'nail polish', '💁': 'person tipping hand', '🙅': 'person gesturing NO', '😁': 'beaming face with smiling eyes'}, {'🎁': 'wrapped gift', '😕': 'confused face'}, {'🙋': 'person raising hand'}, {'☹': 'frowning face'}, {'😔': 'pensive face'}, {'😏': 'smirking face', '😴': 'sleeping face'}, {'😡': 'pouting face'}, {'😡': 'pouting face', '😭': 'loudly crying face'}, {'😂': 'face with tears of joy'}, {'😊': 'smiling face with smiling eyes'}, {'👍': 'thumbs up'}, {'🔫': 'water pistol', '🙅': 'person gesturing NO'}, {'🎁': 'wrapped gift'}, {'👏': 'clapping hands'}, {'😑': 'expressionless face'}, {'😃': 'grinning face with big eyes'}, {'😂': 'face with tears of joy'}, {'😶': 'face without mouth'}, {'👌': 'OK hand'}, {'💘': 'heart with arrow'}, {'🏀': 'basketball', '💯': 'hundred points'}, {'😔': 'pensive face'}, {'😒': 'unamused face'}, {'🎁': 'wrapped gift', '🎅': 'Santa Claus', '👍': 'thumbs up'}, {'😱': 'face screaming in fear'}, {'😜': 'winking face with tongue'}, {'😖': 'confounded face'}, {'😍': 'smiling face with heart-eyes', '😂': 'face with tears of joy'}, {'👎': 'thumbs down', '😑': 'expressionless face'}, {'😄': 'grinning face with smiling eyes'}, {'🚀': 'rocket'}, {'😒': 'unamused face'}, {'✨': 'sparkles'}, {'💃': 'woman dancing', '👸': 'princess', '💋': 'kiss mark', '✨': 'sparkles', '❤': 'red heart'}, {'😄': 'grinning face with smiling eyes', '😒': 'unamused face'}, {'☔': 'umbrella with rain drops', '🎻': 'violin'}, {'😳': 'flushed face'}, {'😑': 'expressionless face'}, {'❤': 'red heart', '😍': 'smiling face with heart-eyes', '💁': 'person tipping hand'}, {'😍': 'smiling face with heart-eyes'}, {'✅': 'check mark button'}, {'💋': 'kiss mark', '❤': 'red heart', '😂': 'face with tears of joy'}, {'🙏': 'folded hands'}, {'🙈': 'see-no-evil monkey', '😘': 'face blowing a kiss', '😭': 'loudly crying face'}, {'😔': 'pensive face'}, {'😛': 'face with tongue'}, {'😒': 'unamused face'}, {'🐶': 'dog face', '🐱': 'cat face'}, {'😩': 'weary face'}, {'🔪': 'kitchen knife', '🔥': 'fire', '😭': 'loudly crying face'}, {'☔': 'umbrella with rain drops', '💦': 'sweat droplets', '💧': 'droplet'}, {'😊': 'smiling face with smiling eyes'}, {'😊': 'smiling face with smiling eyes'}, {'👌': 'OK hand', '👍': 'thumbs up'}, {'😳': 'flushed face'}, {'😳': 'flushed face', '😁': 'beaming face with smiling eyes'}, {'😷': 'face with medical mask'}, {'💜': 'purple heart'}, {'👊': 'oncoming fist'}, {'😐': 'neutral face'}, {'🙈': 'see-no-evil monkey', '😄': 'grinning face with smiling eyes'}, {'😁': 'beaming face with smiling eyes'}, {'😉': 'winking face'}, {'💯': 'hundred points'}, {'🙅': 'person gesturing NO', '😡': 'pouting face'}, {'😂': 'face with tears of joy', '👳': 'person wearing turban'}, {'😘': 'face blowing a kiss'}, {'☺': 'smiling face', '😁': 'beaming face with smiling eyes'}, {'🙏': 'folded hands', '☕': 'hot beverage', '😭': 'loudly crying face'}, {'☔': 'umbrella with rain drops', '⚡': 'high voltage'}, {'😭': 'loudly crying face'}, {'😣': 'persevering face'}, {'😎': 'smiling face with sunglasses'}, {'😂': 'face with tears of joy'}, {'💤': 'zzz', '😴': 'sleeping face', '😕': 'confused face'}, {'😂': 'face with tears of joy'}, {'😖': 'confounded face', '😜': 'winking face with tongue', '😄': 'grinning face with smiling eyes', '😣': 'persevering face', '😫': 'tired face', '😰': 'anxious face with sweat', '😂': 'face with tears of joy'}, {'👎': 'thumbs down'}, {'😭': 'loudly crying face'}, {'😫': 'tired face', '😍': 'smiling face with heart-eyes'}, {'😒': 'unamused face'}, {'😄': 'grinning face with smiling eyes'}, {'😅': 'grinning face with sweat'}, {'😕': 'confused face'}, {'😂': 'face with tears of joy'}, {'👊': 'oncoming fist', '😒': 'unamused face'}, {'😒': 'unamused face'}, {'😖': 'confounded face', '💔': 'broken heart', '😣': 'persevering face'}, {'😜': 'winking face with tongue'}, {'👍': 'thumbs up'}, {'😊': 'smiling face with smiling eyes', '☺': 'smiling face', '😁': 'beaming face with smiling eyes'}, {'🎄': 'Christmas tree', '☺': 'smiling face'}, {'😕': 'confused face'}, {'😒': 'unamused face'}, {'🙏': 'folded hands', '😜': 'winking face with tongue'}, {'😤': 'face with steam from nose'}, {'😘': 'face blowing a kiss'}, {'🙀': 'weary cat', '🎅': 'Santa Claus', '🔫': 'water pistol', '😂': 'face with tears of joy', '😱': 'face screaming in fear'}, {'😰': 'anxious face with sweat'}, {'😂': 'face with tears of joy'}, {'🙈': 'see-no-evil monkey'}, {'😖': 'confounded face'}, {'🍕': 'pizza'}, {'😀': 'grinning face'}, {'🔫': 'water pistol', '🍆': 'eggplant', '😁': 'beaming face with smiling eyes'}, {'😆': 'grinning squinting face'}, {'🔫': 'water pistol', '💻': 'laptop', '💾': 'floppy disk'}, {'👌': 'OK hand'}, {'☔': 'umbrella with rain drops'}, {'😋': 'face savoring food'}, {'😂': 'face with tears of joy'}, {'🇫🇴': 'flag: Faroe Islands'}, {'❤': 'red heart'}, {'💋': 'kiss mark'}, {'👍': 'thumbs up'}, {'😩': 'weary face'}, {'🆘': 'SOS button', '😴': 'sleeping face'}, {'💭': 'thought balloon'}, {'😠': 'angry face', '😤': 'face with steam from nose', '😡': 'pouting face'}, {'☺': 'smiling face'}, {'😎': 'smiling face with sunglasses'}, {'😡': 'pouting face'}, {'😂': 'face with tears of joy'}, {'💪': 'flexed biceps', '👊': 'oncoming fist'}, {'😴': 'sleeping face'}, {'😣': 'persevering face'}, {'😜': 'winking face with tongue', '❤': 'red heart'}, {'👍': 'thumbs up', '😒': 'unamused face'}, {'🙌': 'raising hands', '⚾': 'baseball', '😄': 'grinning face with smiling eyes', '🏆': 'trophy'}, {'👎': 'thumbs down'}, {'😂': 'face with tears of joy'}, {'🔫': 'water pistol', '😡': 'pouting face'}, {'😏': 'smirking face'}, {'😻': 'smiling cat with heart-eyes', '❤': 'red heart', '😂': 'face with tears of joy', '🎉': 'party popper'}, {'💪': 'flexed biceps'}, {'😀': 'grinning face'}, {'👌': 'OK hand'}, {'🙈': 'see-no-evil monkey', '👌': 'OK hand'}, {'❤': 'red heart', '😘': 'face blowing a kiss', '😍': 'smiling face with heart-eyes'}, {'😒': 'unamused face'}, {'💁': 'person tipping hand', '😂': 'face with tears of joy', '😭': 'loudly crying face'}, {'🎵': 'musical note', '💕': 'two hearts'}, {'💤': 'zzz', '😴': 'sleeping face'}, {'🎤': 'microphone'}, {'😝': 'squinting face with tongue'}, {'💀': 'skull'}, {'🙊': 'speak-no-evil monkey', '😁': 'beaming face with smiling eyes', '🎉': 'party popper'}, {'😅': 'grinning face with sweat'}, {'💚': 'green heart', '🛀': 'person taking bath', '👍': 'thumbs up'}, {'😢': 'crying face'}, {'😒': 'unamused face'}, {'😑': 'expressionless face'}, {'💕': 'two hearts'}, {'🐸': 'frog', '☕': 'hot beverage'}, {'🙈': 'see-no-evil monkey'}, {'👍': 'thumbs up', '😒': 'unamused face'}, {'😍': 'smiling face with heart-eyes'}, {'😝': 'squinting face with tongue', '💚': 'green heart', '😍': 'smiling face with heart-eyes', '❤': 'red heart'}, {'🙊': 'speak-no-evil monkey'}, {'🐸': 'frog', '☕': 'hot beverage'}, {'👊': 'oncoming fist'}, {'😒': 'unamused face', '😔': 'pensive face'}, {'😎': 'smiling face with sunglasses'}, {'🙈': 'see-no-evil monkey', '😳': 'flushed face', '😂': 'face with tears of joy'}, {'👌': 'OK hand'}, {'😒': 'unamused face'}, {'💜': 'purple heart'}, {'😂': 'face with tears of joy'}, {'😂': 'face with tears of joy', '😭': 'loudly crying face'}, {'😎': 'smiling face with sunglasses', '😆': 'grinning squinting face'}, {'😏': 'smirking face'}, {'🎄': 'Christmas tree', '🎅': 'Santa Claus'}, {'😤': 'face with steam from nose', '🎄': 'Christmas tree', '😊': 'smiling face with smiling eyes'}, {'😩': 'weary face'}, {'🙈': 'see-no-evil monkey', '😂': 'face with tears of joy'}, {'😡': 'pouting face', '😑': 'expressionless face'}, {'😂': 'face with tears of joy'}, {'😒': 'unamused face'}, {'😳': 'flushed face'}, {'✈': 'airplane'}, {'😩': 'weary face'}, {'💋': 'kiss mark'}, {'😁': 'beaming face with smiling eyes'}, {'😂': 'face with tears of joy', '👊': 'oncoming fist'}, {'😂': 'face with tears of joy'}, {'😊': 'smiling face with smiling eyes'}, {'😂': 'face with tears of joy'}, {'😂': 'face with tears of joy'}, {'🙊': 'speak-no-evil monkey'}, {'🎁': 'wrapped gift', '🎅': 'Santa Claus', '👍': 'thumbs up'}, {'🎧': 'headphone'}, {'😂': 'face with tears of joy'}, {'😏': 'smirking face', '😎': 'smiling face with sunglasses', '🎄': 'Christmas tree'}, {'🐁': 'mouse'}, {'💁': 'person tipping hand'}, {'👍': 'thumbs up', '😃': 'grinning face with big eyes'}, {'🙈': 'see-no-evil monkey', '💕': 'two hearts'}, {'😷': 'face with medical mask'}, {'☁': 'cloud'}, {'😒': 'unamused face'}, {'😣': 'persevering face'}, {'😬': 'grimacing face'}, {'🚓': 'police car', '💀': 'skull'}, {'🙆': 'person gesturing OK'}, {'💣': 'bomb'}, {'😂': 'face with tears of joy'}, {'🍹': 'tropical drink'}, {'😏': 'smirking face'}, {'😂': 'face with tears of joy'}, {'😷': 'face with medical mask', '😒': 'unamused face'}, {'🙈': 'see-no-evil monkey', '🙊': 'speak-no-evil monkey', '😂': 'face with tears of joy'}, {'😝': 'squinting face with tongue'}, {'😊': 'smiling face with smiling eyes'}, {'😞': 'disappointed face', '😔': 'pensive face'}, {'😏': 'smirking face', '🙅': 'person gesturing NO', '👑': 'crown'}, {'😂': 'face with tears of joy'}, {'😜': 'winking face with tongue'}, {'😳': 'flushed face'}, {'😂': 'face with tears of joy'}, {'👍': 'thumbs up'}, {'😘': 'face blowing a kiss'}, {'😁': 'beaming face with smiling eyes'}, {'😒': 'unamused face', '😑': 'expressionless face'}, {'😵': 'knocked-out face', '🔪': 'kitchen knife'}, {'😒': 'unamused face'}, {'😎': 'smiling face with sunglasses', '🎼': 'musical score', '👊': 'oncoming fist', '👏': 'clapping hands'}, {'🎶': 'musical notes', '😊': 'smiling face with smiling eyes'}, {'🚶': 'person walking'}, {'🔌': 'electric plug'}, {'❄': 'snowflake', '🇬🇧': 'flag: United Kingdom'}, {'😂': 'face with tears of joy', '😃': 'grinning face with big eyes'}, {'😭': 'loudly crying face'}, {'😂': 'face with tears of joy'}, {'👌': 'OK hand'}, {'😏': 'smirking face'}, {'😏': 'smirking face', '👊': 'oncoming fist'}, {'♥': 'heart suit'}, {'😒': 'unamused face'}, {'😡': 'pouting face'}, {'🍸': 'cocktail glass', '🔫': 'water pistol', '☺': 'smiling face'}, {'😏': 'smirking face', '😳': 'flushed face'}, {'💃': 'woman dancing', '📚': 'books', '👯': 'people with bunny ears', '📖': 'open book'}, {'💖': 'sparkling heart', '😇': 'smiling face with halo'}, {'😂': 'face with tears of joy'}, {'😊': 'smiling face with smiling eyes'}, {'😔': 'pensive face'}, {'🔫': 'water pistol', '😲': 'astonished face'}, {'💜': 'purple heart'}, {'🙌': 'raising hands', '👍': 'thumbs up', '👏': 'clapping hands'}, {'😘': 'face blowing a kiss'}, {'☺': 'smiling face'}, {'👍': 'thumbs up'}, {'🔜': 'SOON arrow', '➡': 'right arrow', '📷': 'camera'}, {'💜': 'purple heart', '☺': 'smiling face'}, {'😂': 'face with tears of joy'}, {'💕': 'two hearts'}, {'🙌': 'raising hands'}, {'❤': 'red heart'}, {'💁': 'person tipping hand', '😊': 'smiling face with smiling eyes'}, {'🙌': 'raising hands', '💕': 'two hearts', '😘': 'face blowing a kiss'}, {'😒': 'unamused face'}, {'💕': 'two hearts', '💜': 'purple heart'}, {'🍵': 'teacup without handle'}, {'🔥': 'fire', '🔜': 'SOON arrow'}, {'☺': 'smiling face', '🎉': 'party popper'}, {'🙈': 'see-no-evil monkey', '😩': 'weary face', '😂': 'face with tears of joy'}, {'😒': 'unamused face'}, {'😂': 'face with tears of joy'}, {'😪': 'sleepy face', '😞': 'disappointed face', '😕': 'confused face', '😢': 'crying face', '😟': 'worried face'}, {'😂': 'face with tears of joy'}, {'🔥': 'fire'}, {'😍': 'smiling face with heart-eyes', '👍': 'thumbs up'}, {'😉': 'winking face', '😂': 'face with tears of joy', '🍻': 'clinking beer mugs'}, {'😃': 'grinning face with big eyes'}, {'😂': 'face with tears of joy'}, {'😢': 'crying face', '😭': 'loudly crying face'}, {'😅': 'grinning face with sweat'}, {'😘': 'face blowing a kiss', '😁': 'beaming face with smiling eyes'}, {'😘': 'face blowing a kiss'}, {'😁': 'beaming face with smiling eyes'}, {'☺': 'smiling face'}, {'😍': 'smiling face with heart-eyes'}, {'🐣': 'hatching chick', '😂': 'face with tears of joy'}, {'🙈': 'see-no-evil monkey'}, {'😍': 'smiling face with heart-eyes'}, {'😂': 'face with tears of joy'}, {'💁': 'person tipping hand'}, {'✌': 'victory hand'}, {'😂': 'face with tears of joy'}, {'😂': 'face with tears of joy', '😋': 'face savoring food'}, {'🏃': 'person running', '😑': 'expressionless face'}, {'😂': 'face with tears of joy'}, {'😅': 'grinning face with sweat', '😱': 'face screaming in fear'}, {'👐': 'open hands', '😂': 'face with tears of joy'}, {'💕': 'two hearts', '💜': 'purple heart'}, {'💓': 'beating heart'}, {'😂': 'face with tears of joy', '👊': 'oncoming fist'}, {'😑': 'expressionless face'}, {'😜': 'winking face with tongue', '😂': 'face with tears of joy'}, {'💜': 'purple heart'}, {'😳': 'flushed face'}, {'✌': 'victory hand', '🙌': 'raising hands', '😂': 'face with tears of joy'}, {'😡': 'pouting face'}, {'☺': 'smiling face'}, {'💪': 'flexed biceps'}, {'😁': 'beaming face with smiling eyes'}, {'😒': 'unamused face'}, {'😣': 'persevering face'}, {'🎄': 'Christmas tree', '🎅': 'Santa Claus'}, {'😒': 'unamused face'}, {'💚': 'green heart'}, {'🎁': 'wrapped gift', '🎄': 'Christmas tree', '🎅': 'Santa Claus'}, {'😂': 'face with tears of joy'}, {'😂': 'face with tears of joy'}, {'😒': 'unamused face'}, {'😂': 'face with tears of joy'}, {'😩': 'weary face', '😔': 'pensive face'}, {'🙈': 'see-no-evil monkey'}, {'😕': 'confused face'}, {'😁': 'beaming face with smiling eyes'}, {'😩': 'weary face'}, {'👎': 'thumbs down', '👍': 'thumbs up'}, {'❤': 'red heart'}, {'💗': 'growing heart', '🔫': 'water pistol', '😞': 'disappointed face'}, {'🔫': 'water pistol', '😒': 'unamused face'}, {'🎉': 'party popper'}, {'❄': 'snowflake'}, {'😜': 'winking face with tongue'}, {'😁': 'beaming face with smiling eyes'}, {'😉': 'winking face'}, {'🍴': 'fork and knife'}, {'🍟': 'french fries'}, {'🙊': 'speak-no-evil monkey', '😂': 'face with tears of joy'}, {'🎶': 'musical notes', '😘': 'face blowing a kiss', '🎅': 'Santa Claus', '🎉': 'party popper'}, {'💃': 'woman dancing', '✋': 'raised hand'}, {'👌': 'OK hand'}, {'✌': 'victory hand'}, {'⛄': 'snowman without snow', '🚍': 'oncoming bus', '😋': 'face savoring food', '❄': 'snowflake'}, {'😳': 'flushed face'}, {'🙊': 'speak-no-evil monkey', '📚': 'books', '👯': 'people with bunny ears'}, {'😒': 'unamused face'}, {'🚑': 'ambulance', '🚒': 'fire engine', '😴': 'sleeping face'}, {'👍': 'thumbs up', '😃': 'grinning face with big eyes'}, {'😖': 'confounded face'}, {'✈': 'airplane', '❤': 'red heart', '🎄': 'Christmas tree'}, {'😂': 'face with tears of joy'}, {'💰': 'money bag'}, {'😴': 'sleeping face'}, {'✨': 'sparkles', '🙇': 'person bowing'}, {'😒': 'unamused face'}, {'🙈': 'see-no-evil monkey', '👌': 'OK hand', '😆': 'grinning squinting face', '☺': 'smiling face'}, {'⭕': 'hollow red circle', '👏': 'clapping hands', '❌': 'cross mark', '🙌': 'raising hands', '💜': 'purple heart', '🙏': 'folded hands', '👈': 'backhand index pointing left', '👉': 'backhand index pointing right'}, {'😜': 'winking face with tongue'}, {'😬': 'grimacing face', '💜': 'purple heart', '💕': 'two hearts'}, {'✌': 'victory hand', '😖': 'confounded face', '😔': 'pensive face'}, {'😷': 'face with medical mask', '😣': 'persevering face'}, {'😁': 'beaming face with smiling eyes'}, {'😎': 'smiling face with sunglasses'}, {'😂': 'face with tears of joy'}, {'💅': 'nail polish'}, {'😔': 'pensive face'}, {'👤': 'bust in silhouette'}, {'💩': 'pile of poo'}, {'👑': 'crown'}, {'👌': 'OK hand'}, {'😳': 'flushed face'}, {'😂': 'face with tears of joy'}, {'💀': 'skull', '😂': 'face with tears of joy'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha-5_iKBq6a2"
      },
      "source": [
        "all_keys = set().union(*(d.keys() for d in f))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JoF2GjBrCmL",
        "outputId": "1593fc56-5b19-4000-9c86-ba973852de34"
      },
      "source": [
        "print(all_keys)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'😘', '📚', '💨', '😢', '😁', '🌴', '🙈', '😶', '💓', '💻', '🚒', '💁', '🏆', '😐', '😄', '🇫🇴', '🙆', '💰', '🍸', '😰', '😑', '✨', '⚡', '💧', '👉', '🎁', '😩', '☁', '📷', '✋', '💣', '🙅', '😤', '😻', '🙋', '✌', '😲', '😒', '👸', '😫', '😷', '🎄', '🎼', '👤', '😀', '🆘', '😊', '😴', '😋', '👈', '😉', '❄', '👐', '🍕', '😝', '🏀', '🇬🇧', '😎', '👌', '👑', '😇', '😠', '🎶', '👏', '🚑', '💩', '❌', '😟', '💗', '💅', '😂', '🔪', '⚾', '💯', '🐣', '🚓', '🙏', '😏', '🍷', '🔫', '💤', '⭕', '🍹', '😛', '😣', '💭', '📖', '🐶', '⛄', '😪', '☹', '💜', '🔜', '✅', '💖', '💚', '😱', '🌏', '🎵', '🎻', '🚍', '🐁', '🍻', '😡', '🎤', '🔌', '😬', '👎', '🙇', '🍴', '🙊', '😵', '💔', '💾', '🏃', '♥', '💦', '😔', '😖', '💕', '😞', '💘', '😅', '❤', '🍆', '🚀', '🚶', '🙀', '🙌', '✈', '☔', '😆', '👍', '💋', '😳', '🐸', '👭', '😭', '😕', '🐱', '🎉', '🍟', '👯', '🔥', '🛀', '👊', '💃', '💀', '💪', '☺', '➡', '☀', '🎧', '😜', '🎅', '😃', '🍵', '👳', '😍', '☕'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNmV_fsqsWqL",
        "outputId": "c1b87d3e-5c95-40dd-b99f-13202b371b3d"
      },
      "source": [
        "print(len(all_keys))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH_JM7eP769R"
      },
      "source": [
        "import emoji\n",
        "def extract_emojis(s):\n",
        "    return ''.join((' '+c+' ') if c in emoji.UNICODE_EMOJI['en'] else c for c in s)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muaW_AjC79x0"
      },
      "source": [
        "df['Tweet'] = df['Tweet'].apply(extract_emojis)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFDzUomz7-gc"
      },
      "source": [
        "df.columns = df.columns.str.lstrip()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxHee5q38BGG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zxjTupWd3HlA",
        "outputId": "96e00ab0-a3eb-4021-c28b-8963f150134c"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Tweet text</th>\n",
              "      <th>Emoji list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>sweet united nations video just in time for ch...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>we are rumored to have talked to erv is agent...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>hey there nice to see you minnesotand winter w...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3 episodes left i am dying over here</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>i cannot breathe was chosen as the most notabl...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Label                                         Tweet text Emoji list\n",
              "0      1  sweet united nations video just in time for ch...         []\n",
              "1      1   we are rumored to have talked to erv is agent...         []\n",
              "2      1  hey there nice to see you minnesotand winter w...         []\n",
              "3      0               3 episodes left i am dying over here         []\n",
              "4      1  i cannot breathe was chosen as the most notabl...         []"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541966424
        },
        "id": "4PDO5OJ2ztpt"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'distilbert-base-uncased'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541969740
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163,
          "referenced_widgets": [
            "1414cb67f79a40d1958c13fae11c7cfa",
            "f6046ff8bdb949eaae21007c7126d39b",
            "785b5628bbe7484f9e0c75e070acd37a",
            "cd83d2a1176a4e11bbede12e0149598e",
            "00d6bd89dec94481a113d8e4877d9e0c",
            "bd629ec788774b7892c97e395cd40886",
            "33dcdbd0e4b34995a3848676bbd4a62f",
            "2313739c911240e9ac5ec17c7be9f30c",
            "b83ad895ca38474da78b17c496789ad7",
            "baa1247be46a4841aa31f9d7889b1a5a",
            "d4038c61bd8f4f1aa1bb1814218e0a04",
            "2ff80a98ca3642f2ba73bbacdc17a74f",
            "55ab24fa453748f28765dd7b6176ccc8",
            "5925ca86e94c4b83b0c344ec629995fd",
            "5137e727dc074a01b5abbabd4a353c93",
            "7740d44323284511b78bff37cd4aee1f",
            "08a03ac77e7646e098a986b326545541",
            "6c3e93d832b84456b5c1d92964e9a271",
            "290b00224c424bcab4ad237e1e38a6c5",
            "0830337f90dc4433b173b159d9936f39",
            "646372a1117a493ba3838a45b8f84fcc",
            "ec485c02075d466288a42d38a51d33b2",
            "db027e78ac5248eebc4362da51866418",
            "042e08fff6d04dfe8547dba5fb8160fa",
            "5bd5d2e0e4394e33a7c868367542ccb3",
            "1a05aa871560464a81b7839a7c6bf9f1",
            "0097a729070044e9b96c87d4e96d33b8",
            "a026fd9f42bd4953b42e2906e404bc7b",
            "4aae0ca92c7d40e0b31595ced1b2aa6a",
            "b37d7a7076f84a91a97a1dccfdcb634e",
            "187287581a2c4e87af2eeebb83f6ad3b",
            "3e42913f27f346d79f6fdcfbe79c2feb",
            "e5c119e5b5e245afaa7d6851ccadf23e",
            "7b39a08e09424a4caf76b40cf02425b4",
            "41cc5f4c3d804548a743524efe8774b1",
            "3700f0b2044b4e0cb42e66f1933fdad8",
            "df01db37588943bb96d2a4e1f7ac41c3",
            "49fc123979974188b96befbaad7cf96e",
            "205170b224fa4a4f8be3039eb8344e25",
            "a351ef5d72834407b5e84ba8ec429b7a",
            "8cbe91dd2f8640c9a1553cdd2dd0afc8",
            "de1cf9289d3843ed93ba12295fc3c967",
            "35b92656520749c891b53df6f4d33511",
            "3e6eb4940d014539b0bbfb2bdb3811d1"
          ]
        },
        "id": "EMPaF5ANztpt",
        "outputId": "8dea4682-1841-40d7-fcae-69d9676334fc"
      },
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
        "tokenizer.add_tokens(['⛄', '👉', '💅', '🔥', '😅', '🙆', '✅', '💻', '☕', '🛀', '🎄', '⚾', '😏', '💧', '🇫🇴', '😱', '😔', '🙌', '😬', '🎵', '😎', '😐', '🏀', '👏', '🍻', '🎶', '🚀', '❄', '😶', '😷', '😴', '🍷', '☀️', '😣', '📖', '💨', '👳', '💓', '🔜', '🏃', '☔', '😋', '🎁', '😲', '🙊', '💕', '🐁', '🌴', '🍴', '✈️', '💁', '🚍', '🙅', '🚒', '🍹', '🌏', '✋', '🙏', '🎻', '👑', '🍟', '⚡', '💋', '🆘', '💤', '🎧', '😖', '❄️', '👸', '☀', '🎉', '😩', '😢', '📷', '😤', '😑', '👈', '😍', '🍸', '💃', '😒', '💪', '✌️', '😝', '🍵', '👐', '🔫', '🏆', '🚑', '💣', '🎤', '💦', '😞', '🎅', '😭', '🍕', '💜', '💗', '😕', '😠', '😄', '🐸', '☺️', '♥', '💚', '😘', '🎼', '💭', '🐱', '❤', '☺', '❤️', '😃', '😪', '🙋', '📚', '😛', '🚓', '😡', '😁', '💰', '🍆', '😇', '😂', '✨', '👌', '☁', '🐶', '🐣', '😟', '💘', '👯', '🇬🇧', '😆', '⭕', '💔', '😉', '➡️', '💩', '🙀', '😵', '🙈', '👊', '👤', '💯', '😫', '🙇', '💾', '💀', '😊', '😰', '😳', '👎', '😜', '😀', '☹', '🔌', '🔪', '😻', '🚶', '👭', '💖', '👍', '❌'])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1414cb67f79a40d1958c13fae11c7cfa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ff80a98ca3642f2ba73bbacdc17a74f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db027e78ac5248eebc4362da51866418",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7b39a08e09424a4caf76b40cf02425b4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "163"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541972549
        },
        "id": "CdB1Fa5Bztpt"
      },
      "source": [
        "sample_txt = 'auntie just called and said shes on her wayi better get dressed then 😲 😂 😭'"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541975382
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KRki6qaztpu",
        "outputId": "543a278a-d727-4b0f-b6b0-479ad1a92a8c"
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f' Sentence: {sample_txt}')\n",
        "print(f'   Tokens: {tokens}')\n",
        "print(f'Token IDs: {token_ids}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Sentence: auntie just called and said shes on her wayi better get dressed then 😲 😂 😭\n",
            "   Tokens: ['aunt', '##ie', 'just', 'called', 'and', 'said', 'she', '##s', 'on', 'her', 'way', '##i', 'better', 'get', 'dressed', 'then', '😲', '😂', '😭']\n",
            "Token IDs: [5916, 2666, 2074, 2170, 1998, 2056, 2016, 2015, 2006, 2014, 2126, 2072, 2488, 2131, 5102, 2059, 30565, 30644, 30616]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541980729
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TGOBaXEztpw",
        "outputId": "82b05a60-621e-481c-cd35-b053d3d44589"
      },
      "source": [
        "encoding = tokenizer.encode_plus(\n",
        "  sample_txt,\n",
        "  max_length=32,\n",
        "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',  # Return PyTorch tensors\n",
        ")\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541984214
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnIUMAqDztpx",
        "outputId": "4e474281-a359-42f0-f76c-ca28a0bd2ec5"
      },
      "source": [
        "print(len(encoding['input_ids'][0]))\n",
        "encoding['input_ids'][0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  5916,  2666,  2074,  2170,  1998,  2056,  2016,  2015,  2006,\n",
              "         2014,  2126,  2072,  2488,  2131,  5102,  2059, 30565, 30644, 30616,\n",
              "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541986847
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG59VX9Jztpy",
        "outputId": "fc8b5dcd-c9ad-41ef-cf46-e2b92766fe77"
      },
      "source": [
        "print(len(encoding['attention_mask'][0]))\n",
        "encoding['attention_mask']"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541989596
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8u_nUjq-ztpy",
        "outputId": "67973342-6589-428a-8534-96290c7d51fb"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]',\n",
              " 'aunt',\n",
              " '##ie',\n",
              " 'just',\n",
              " 'called',\n",
              " 'and',\n",
              " 'said',\n",
              " 'she',\n",
              " '##s',\n",
              " 'on',\n",
              " 'her',\n",
              " 'way',\n",
              " '##i',\n",
              " 'better',\n",
              " 'get',\n",
              " 'dressed',\n",
              " 'then',\n",
              " '😲',\n",
              " '😂',\n",
              " '😭',\n",
              " '[SEP]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]',\n",
              " '[PAD]']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541992915
        },
        "id": "mZDQdBGXztpz"
      },
      "source": [
        "token_lens = []\n",
        "\n",
        "for txt in df['Tweet']:\n",
        "  tokens = tokenizer.encode(txt, max_length=256)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541994652
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "4TcEmypFztp0",
        "outputId": "7deccf80-499c-40c4-df71-6205b794e96c"
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 256]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541996528
        },
        "id": "YHFiORafztp1"
      },
      "source": [
        "MAX_LEN = 128"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628541999181
        },
        "id": "CMuzinY3ztp1"
      },
      "source": [
        "class SarcasmDataset(Dataset):\n",
        "\n",
        "  def __init__(self, tweets, targets, tokenizer, max_len):\n",
        "    self.tweets = tweets\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tweets)\n",
        "  \n",
        "  def __getitem__(self, item):\n",
        "    tweet = str(self.tweets[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      tweet,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'tweet_text': tweet,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542000583
        },
        "id": "14LqRdijztp2"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7msK5fVwEsGd",
        "outputId": "1b23ef6b-0897-4929-d7a0-e3409714d587"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542012951
        },
        "id": "Z9zIi1Ohztp2"
      },
      "source": [
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size=0.3, random_state=RANDOM_SEED)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542018012
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXtoaygLztp2",
        "outputId": "d8cea283-470c-468f-8400-7f596f593410"
      },
      "source": [
        "df_train.shape, df_val.shape, df_test.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3052, 3), (534, 3), (230, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542020610
        },
        "id": "3_O37NR9ztp3"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = SarcasmDataset(\n",
        "    tweets=df.Tweet.to_numpy(),\n",
        "    targets=df.Label.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542023124
        },
        "id": "wgyQZJnWztp4"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542025689
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btiS9udFztp4",
        "outputId": "febb3f15-3b4b-417a-942f-fe2ede299563"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['tweet_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542028031
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMU_H5e7ztp5",
        "outputId": "e77986a2-e0e2-4504-fc16-0d892c132f01"
      },
      "source": [
        "print(data['input_ids'].shape)\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542051315
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143,
          "referenced_widgets": [
            "7fd8bd2746cd47d78c1da902352c214c",
            "f311d86da606466a84d8b2cd7c848307",
            "03a665462ca04b069fd9ede5c100b9e7",
            "d3724f9c07b14073a129ef0ff1d1eef0",
            "89bd68bb5a6e4882a8e7cfed1bbdddbd",
            "35e47b1f49eb45f5990f4f960465758a",
            "02f957beded84771b0bb4c4aed91a327",
            "7b7e98292cee44938e5143a05b6e8a4b",
            "074b808445254306a0b8b2b8fe547069",
            "4e3c29470b704cddbe9ed5161a0fb971",
            "408745d17ad247239760cd90cca8669c"
          ]
        },
        "id": "sTTaFbSBztp5",
        "outputId": "254eb473-4abb-43b1-9363-b38997495407"
      },
      "source": [
        "bert_model_1 = DistilBertModel.from_pretrained(PRE_TRAINED_MODEL_NAME,output_hidden_states=True)\n",
        "bert_model_1.resize_token_embeddings(len(tokenizer))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7fd8bd2746cd47d78c1da902352c214c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(30685, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542052197
        },
        "id": "lNE8FFcDztp6"
      },
      "source": [
        "last_hidden_state, pooled_output = bert_model_1(\n",
        "  input_ids=encoding['input_ids'], \n",
        "  attention_mask=encoding['attention_mask'],\n",
        "  return_dict = False\n",
        ")"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542053097
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3NOI5vhztp6",
        "outputId": "b2d05e8d-0600-4d4d-f3f9-5b19c7f2738d"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542057526
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvGHv4fAztp7",
        "outputId": "9f40cab6-1418-4033-980a-935c95ad9510"
      },
      "source": [
        "bert_model_1.config.hidden_size"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542059145
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "5q8PdTsdztp7",
        "outputId": "1d8c6c55-db6d-4c70-bbba-27a7463542a0"
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-d5f0470db3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpooled_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542062775
        },
        "id": "ezq-1nJzztp8"
      },
      "source": [
        "class SarcasmClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SarcasmClassifier, self).__init__()\n",
        "    self.l1 = bert_model_1\n",
        "    self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "    self.dropout = torch.nn.Dropout(0.3)\n",
        "    self.classifier = torch.nn.Linear(768, 2)\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    hidden_state = output_1[0]\n",
        "    pooler = hidden_state[:, 0]\n",
        "    pooler = self.pre_classifier(pooler)\n",
        "    pooler = torch.nn.ReLU()(pooler)\n",
        "    pooler = self.dropout(pooler)\n",
        "    output = self.classifier(pooler)\n",
        "    return output\n",
        "    "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543480185
        },
        "id": "wnKxnnaqztp8"
      },
      "source": [
        "class_names=['1', '0']"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542067080
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8taxt9wuztp9",
        "outputId": "b5dd4b82-ea01-4712-a4ed-08880d58d62e"
      },
      "source": [
        "len(class_names)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgWI4j3aSwDl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "e6e661dd-ae29-496c-db4e-f924745ccc5d"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-17185ab12843>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = BertForSequenceClassification.from_pretrained(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Use the 12-layer BERT model, with an uncased vocab.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# The number of output labels--2 for binary classification.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0;31m# You can increase this for multi-class tasks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moutput_attentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Whether the model returns attentions weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'BertForSequenceClassification' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542100563
        },
        "id": "VaWv_jkoztp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8e1882-25bc-473a-f879-78e7617695d7"
      },
      "source": [
        "model = SarcasmClassifier(len(class_names))\n",
        "model.to(device)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SarcasmClassifier(\n",
              "  (l1): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30685, 768)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (1): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (2): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (3): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (4): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "        (5): TransformerBlock(\n",
              "          (attention): MultiHeadSelfAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542105754
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzSibseqztp9",
        "outputId": "61b2c52e-0582-4a23-b712-cd285e7b015d"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq length"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128])\n",
            "torch.Size([32, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542108826
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8g-06PX2ztp-",
        "outputId": "4f157005-2417-4380-f909-6cb1590864c6"
      },
      "source": [
        "F.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4907, 0.5093],\n",
              "        [0.4763, 0.5237],\n",
              "        [0.4918, 0.5082],\n",
              "        [0.5263, 0.4737],\n",
              "        [0.5142, 0.4858],\n",
              "        [0.5256, 0.4744],\n",
              "        [0.5418, 0.4582],\n",
              "        [0.4956, 0.5044],\n",
              "        [0.5061, 0.4939],\n",
              "        [0.5340, 0.4660],\n",
              "        [0.5131, 0.4869],\n",
              "        [0.4946, 0.5054],\n",
              "        [0.4903, 0.5097],\n",
              "        [0.5113, 0.4887],\n",
              "        [0.5048, 0.4952],\n",
              "        [0.5408, 0.4592],\n",
              "        [0.5397, 0.4603],\n",
              "        [0.5225, 0.4775],\n",
              "        [0.5183, 0.4817],\n",
              "        [0.4848, 0.5152],\n",
              "        [0.5118, 0.4882],\n",
              "        [0.5292, 0.4708],\n",
              "        [0.5252, 0.4748],\n",
              "        [0.5032, 0.4968],\n",
              "        [0.5278, 0.4722],\n",
              "        [0.5248, 0.4752],\n",
              "        [0.5140, 0.4860],\n",
              "        [0.4306, 0.5694],\n",
              "        [0.5158, 0.4842],\n",
              "        [0.5042, 0.4958],\n",
              "        [0.5463, 0.4537],\n",
              "        [0.4806, 0.5194]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxaeD6kaLzBN"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "                                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2.7e-5, eps= 1e-8)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542133125
        },
        "id": "iL7bzkOxztp-"
      },
      "source": [
        "#EPOCHS = 4\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, eps= 1e-8)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542136704
        },
        "id": "MS46adZbztp_"
      },
      "source": [
        "def train_epoch(\n",
        "  model, \n",
        "  data_loader, \n",
        "  loss_fn, \n",
        "  optimizer, \n",
        "  device, \n",
        "  scheduler, \n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  \n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"].to(device)\n",
        "\n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628542138373
        },
        "id": "543L-EZfztp_"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9XPrBcpztqA",
        "outputId": "f9c5200c-67c3-4b66-b96b-3981cb18edcb"
      },
      "source": [
        "%%time\n",
        "\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,    \n",
        "    loss_fn, \n",
        "    optimizer, \n",
        "    device, \n",
        "    scheduler, \n",
        "    len(df_train)\n",
        "  )\n",
        "\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn, \n",
        "    device, \n",
        "    len(df_val)\n",
        "  )\n",
        "\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_semeval_distilbert_run2.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6700206268578768 accuracy 0.5773263433813892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6319024562835693 accuracy 0.6367041198501873\n",
            "\n",
            "Epoch 2/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.5444408707941572 accuracy 0.7264089121887287\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6304372496464673 accuracy 0.6629213483146067\n",
            "\n",
            "Epoch 3/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.4028433876422544 accuracy 0.8292922673656619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.6850019518066855 accuracy 0.6704119850187266\n",
            "\n",
            "Epoch 4/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.2950843176028381 accuracy 0.8810615989515073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7745270062895382 accuracy 0.6647940074906367\n",
            "\n",
            "Epoch 5/5\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.21638433348077038 accuracy 0.9252948885976409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val   loss 0.7637376802809098 accuracy 0.6779026217228464\n",
            "\n",
            "CPU times: user 1min 41s, sys: 3.41 s, total: 1min 45s\n",
            "Wall time: 1min 45s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543120514
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "zrAPw73lztqA",
        "outputId": "77fd936c-30b2-4c54-9f03-6b8f179448db"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543125557
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "-o0p2u2QztqC",
        "outputId": "09be6fce-501e-4714-a127-8a9f89ceb64d"
      },
      "source": [
        "plt.plot(history['train_loss'], label='train loss')\n",
        "plt.plot(history['val_loss'], label='validation loss')\n",
        "\n",
        "plt.title('Training Loss vs Validation Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543205227
        },
        "id": "nOJ01_qCztqC"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  \n",
        "  tweet_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      texts = d[\"tweet_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "\n",
        "      probs = F.softmax(outputs, dim=1)\n",
        "\n",
        "      tweet_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(probs)\n",
        "      real_values.extend(targets)\n",
        "\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return tweet_texts, predictions, prediction_probs, real_values"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543218167
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiBUsFAiztqC",
        "outputId": "eb820d2d-dfa1-4f84-f9a6-e4546b7c5b7a"
      },
      "source": [
        "y_tweet_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  test_data_loader\n",
        ")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543488243
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4846MMi3ztqD",
        "outputId": "da13522f-8123-439e-a733-b20c90397622"
      },
      "source": [
        "print(classification_report(y_test, y_pred,target_names=class_names))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.66      0.66      0.66       118\n",
            "           0       0.64      0.63      0.64       112\n",
            "\n",
            "    accuracy                           0.65       230\n",
            "   macro avg       0.65      0.65      0.65       230\n",
            "weighted avg       0.65      0.65      0.65       230\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543503220
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1EF_wkj9ztqD",
        "outputId": "447b0038-be3a-4a4d-d87b-ab9d1c69c2de"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543511691
        },
        "id": "_xjLqo2mztqE"
      },
      "source": [
        "idx = 2\n",
        "\n",
        "tweet_text = y_tweet_texts[idx]\n",
        "true_sentiment = y_test[idx]\n",
        "pred_df = pd.DataFrame({\n",
        "  'class_names': class_names,\n",
        "  'values': y_pred_probs[idx]\n",
        "})"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543513717
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0xuGj36ztqE",
        "outputId": "cf4371fc-f8c0-41ba-ad79-ee2775fde7f9"
      },
      "source": [
        "print(\"\\n\".join(wrap(tweet_text)))\n",
        "print()\n",
        "print(f'True sentiment: {class_names[true_sentiment]}')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "why is paper so sharp someone should put a ban on paper\n",
            "liberalmentality\n",
            "\n",
            "True sentiment: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543650153
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "YsmlzNc6ztqF",
        "outputId": "2224ca20-28fb-4569-aa79-72ee867a1a47"
      },
      "source": [
        "sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "plt.ylabel('sentiment')\n",
        "plt.xlabel('probability')\n",
        "plt.xlim([0, 1]);"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628279937778
        },
        "id": "Hvi_vCLqztqF"
      },
      "source": [
        "review_text = \"Oh thank GOD our entire office email system is down... the day of a big event. Santa you know JUST what to get me for xmas\""
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543657871
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZsjnnpxztqG",
        "outputId": "688f7679-b88a-4b90-c930-80b898d8aa51"
      },
      "source": [
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1628543661688
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY99Dxm_ztqG",
        "outputId": "65403832-2892-4441-8a6d-218ad93ae799"
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Tweet text: {review_text}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet text: Oh thank GOD our entire office email system is down... the day of a big event. Santa you know JUST what to get me for xmas\n",
            "Sentiment  : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "d7iMBomJztqH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}